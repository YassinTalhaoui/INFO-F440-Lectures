{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 4\n",
    "\n",
    "# March 6, 2023\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "A streaming algorithm is one that looks at the data once, one element at a time. The idea is that it does not store the data but stores some very small amount of data that allows it to compute what it wants. \n",
    "\n",
    "Streaming algorithms are of use not only in their original context where data is going by so quickly that you can not store it, but also in the big data context where you have a data set that is so big that you don't want to look at it more than once and copying or moving it is out of the question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming and iterators\n",
    "\n",
    "In python (and other similar languages) the construct `for x in X` works like a stream, where the data is not stored and you can look at each item in `X` once. How do you create such a stream? One way is to use what python calls a generator, where each element of the stream is produced with a `yield` statement. Execution then alternates between the `for` loop and the generator, and nothing is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SomeRandom\n",
      "74\n"
     ]
    }
   ],
   "source": [
    "def someRandom(maxcount,maxnum,debug=False):\n",
    "    for i in range(random.randint(1,maxcount)):\n",
    "        if debug:\n",
    "            print(\"SomeRandom\")\n",
    "        yield(random.randint(0,maxnum))\n",
    "        \n",
    "for x in someRandom(10,100,True):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SomeRandom\n",
      "Average\n",
      "SomeRandom\n",
      "Average\n",
      "SomeRandom\n",
      "Average\n",
      "SomeRandom\n",
      "Average\n",
      "SomeRandom\n",
      "Average\n",
      "SomeRandom\n",
      "Average\n",
      "SomeRandom\n",
      "Average\n",
      "572.0\n"
     ]
    }
   ],
   "source": [
    "# Good code to compute the average\n",
    "# See how execution alternates back and forth from the generator\n",
    "# And nothing is stored\n",
    "l=0\n",
    "s=0\n",
    "for x in someRandom(10,1000,debug=True):\n",
    "    print(\"Average\")\n",
    "    s+=x\n",
    "    l+=1\n",
    "print(s/l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SomeRandom\n",
      "SomeRandom\n",
      "SomeRandom\n",
      "SomeRandom\n",
      "SomeRandom\n",
      "SomeRandom\n",
      "SomeRandom\n",
      "A created\n",
      "782.2857142857143\n"
     ]
    }
   ],
   "source": [
    "# Bad code to compute the average\n",
    "# All values are saved in A\n",
    "A=[x for x in someRandom(10,1000,debug=True)]\n",
    "print(\"A created\")\n",
    "print(sum(A)/len(A))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Median streaming\n",
    "\n",
    "In order to compute the median in the streaming model, you can use exactly the same sampling method we discussed previously. The only question is how to get a uniform sample in the streaming model. The answer given a stream of data $x_1, \\ldots x_n$, at step $i$ replace the current sample with $x_i$ with probability $\\frac{1}{i}$. Thus the chance that $x_i$ is chosen, is the chance that $x_i$ is picked and the chance that $x_j$, $j>i$ are all not picked.\n",
    "\n",
    "$$\n",
    "\\displaystyle \\frac{1}{i} \\prod_{j={i+1}}^n \\frac{j-1}{j}\n",
    "$$\n",
    "\n",
    "This telescopes to $\\frac{1}{n}$:\n",
    "\n",
    "$$\n",
    "\\displaystyle  \\frac{\\prod_{j={i+1}}^n (j-1)}{i\\prod_{j={i+1}}^n j}\n",
    "=\n",
    "\\displaystyle  \\frac{\\prod_{j={i}}^{n-1} j}{n\\prod_{j={i}}^{n-1} j}\n",
    "=\\frac{1}{n}$$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Distinct elements: Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation:\n",
    "\n",
    "- Let $d$ be the number of distinct elements. Name them $x_1,\\ldots x_d$.\n",
    "- Let $z(x_i)$ be the number of trailing zeros in the binary representation of $h(x_i)$\n",
    "- Let $z = max_i z(x_i)$. This is the maximum number of zeros\n",
    "- Let $\\hat{d} = 2^{z+\\frac{1}{2}}$. This is the output approximation for $d$.\n",
    "\n",
    "What we want to prove is that usually $\\hat{d}$ is close to $d$. Specifically we will bound that they are within a factor of 3 of each other.\n",
    "\n",
    "Let us proceed with the upper bound. We want to ask, what is the chance that $\\hat{d}\\geq 3d$. As usual we want to break things down into indicator random variables so that we can use linearity of expectation.\n",
    "\n",
    "We define the indicator random variable $z_j(x_i)$ which is true if \n",
    "$z(x_i)\\geq j$. Note that since the chance that a random binary string ends with $i$ 0's is $\\frac{1}{2^i}$, $E[z(x_i)] = \\frac{1}{2^i}$. We let $Y_j = \\sum_{i=1}^d z_j(x_i)$. Thus $Y_j$ is the number of distinct items in the stream that have zeros values at least $j$. Thus if $z$, the maximum number of zeros is $j$, we known $Y_j \\geq 1$ and $Y_{j+1}=0$. Thus we can relate the maximum with the sum, which we know how to deal with.\n",
    "\n",
    "Let's look at the chance that $\\hat{d}$ is too big by a factor of three.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&P[\\hat{d} \\geq 3d] \\\\\n",
    "&= P[ 2^{z+\\frac{1}{2}} \\geq 2^{\\log (3d)} ]\n",
    "\\\\\n",
    "&= P[ z+\\frac{1}{2} \\geq \\log (3d)]\n",
    "\\\\\n",
    "&= P[ z \\geq \\log (3d)-\\frac{1}{2}]\n",
    "\\\\\n",
    "&= P[Y_{\\log (3d)- \\frac{1}{2}} \\geq 1]\n",
    "\\\\\n",
    "&\\leq  \\frac{E[Y_{\\log (3d)- \\frac{1}{2}}]}{1}\n",
    "& \\text{Markov: }Pr[X\\geq  a ] \\leq \\frac{E[X]}{a}\n",
    "\\\\\n",
    "& =  E\\left[\\sum_{i}^d z_{\\log (3d)- \\frac{1}{2}}(x_i) \\right]\n",
    "&\\text{As }Y_j = \\sum_{i}^d z_j(x_i)\n",
    "\\\\\n",
    "& =  \\sum_{i}^d E[z_{\\log (3d)- \\frac{1}{2}}(x_i) ]\n",
    "\\\\\n",
    "& =  \\sum_{i}^d \\frac{1}{2^{\\log (3d)- \\frac{1}{2} }}\n",
    "\\\\\n",
    "& =  \\sum_{i}^d \\frac{\\sqrt{2}}{3d} \n",
    "\\\\\n",
    "& =  \\frac{\\sqrt{2}}{3}\\approx 47\\%\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Next, Let's look at the chance that $\\hat{d}$ is too small. *We did not do the math for this in class, and it is a little different than the too big case*.\n",
    "As Markov is useless in this case, we introduce the third commonly used inequality:\n",
    "Chebyshev, which bounds how likely a random variable can be far from its expected value as a function of its variance: \n",
    "\n",
    "$$ Pr[ | X - E[X] | \\geq k ] \\leq \\frac{Var[X]}{k^2}$$\n",
    "\n",
    "The variance $Var[X]$ is has the easy-to-use formula of $E[X]^2-E[X^2]$. This is very easy to use for indicator random variables, as these are always 0 or 1, which are the two numbers that don't change when you square them; this for indicator random variables $E[X^2]$ is $E[X]$. Finally, for independent variables $Var[X+Y]=Var[X]+Var[Y]$\n",
    "\n",
    "Ok, so lets look at the chance that $\\hat{d}$ is too small by a factor of 3.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "&P[\\hat{d} \\leq \\frac{d}{3}] \\\\\n",
    "&= P[ 2^{z+\\frac{1}{2}} < 2^{\\log \\frac{d}{3}} ]\n",
    "\\\\\n",
    "&= P[ z+\\frac{1}{2} < \\log \\frac{d}{3}]\n",
    "\\\\\n",
    "&= P[Y_{\\log \\frac{d}{3}+ \\frac{1}{2}} = 0 ]\n",
    "\\\\\n",
    "&\\leq  P[ | Y_{\\log \\frac{d}{3}+ \\frac{1}{2}} - E[Y_{\\log \\frac{d}{3}+ \\frac{1}{2}}]|  \\geq  E[Y_{\\log \\frac{d}{3}+ \\frac{1}{2}}] ]\n",
    "\\\\\n",
    "&\\leq  \\frac{Var[Y_{\\log \\frac{d}{3}+ \\frac{1}{2}}]}{E[Y_{\\log \\frac{d}{3}+ \\frac{1}{2}}]^2}\n",
    "& \\text{Chebyshev: }Pr[ | X - E[X] | \\geq k ] \\leq \\frac{Var[X]}{k^2}\n",
    "\\\\\n",
    "&\\leq  \\frac{E[Y_{\\log \\frac{d}{3}+ \\frac{1}{2}}]}{E[Y_{\\log \\frac{d}{3}+ \\frac{1}{2}}]^2}\n",
    "& \\text{*}\n",
    "\\\\\n",
    "&\\leq  \\frac{1}{E[Y_{\\log \\frac{d}{3}+ \\frac{1}{2}}]}\n",
    "\\\\\n",
    "&\\leq  \\frac{\\sqrt{2}}{3}\n",
    "&\\text{As  above, $E[Y_m] = \\frac{d}{2^m}$}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Point * is because $Var[Y_m]=Var[\\sum_{i}^d z_j(x_i)]=\\sum_{i}^d Var [z_m(x_i)] =\n",
    "\\sum_{i}^d (E[ z_m(x_i)^2]-E[ z_m(x_i)]^2 )\\leq \\sum_{i}^d E[ z_m(x_i)^2]= \\sum_{i}^d E[ z_m(x_i)] = E[\\sum_{i}^d z_m(x_i)] = E[Y_m]\n",
    "$\n",
    "\n",
    "So, we have the probability that $\\hat{d}$ is within a factor of 3 of the real value of $d$ is $1-\\frac{2 \\sqrt{2}}{3}\\approx 0.057$.\n",
    "A 6% success rate is hardly impressive. But, by using several independent computations of the distinct elements, and taking the median value, we can boost the success rate. This is exactly the same as the approximate median finding algorithm with $\\epsilon= 1-\\frac{2 \\sqrt{2}}{3}\\approx 0.057$. \n",
    "\n",
    "Thus, using the formula from the previous lecture, to get an answer that is correct within a factor of 3 with an at most $\\gamma$ chance of failure, one should run the sketch\n",
    "$\\frac{6}{(0.057)^2} \\ln \\frac{2}{\\gamma}$\n",
    "times in parallel and take the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 55.322849003767146\n",
      "0.01 97.84519605813549\n",
      "0.001 140.36754311250382\n",
      "1e-05 225.41223722124053\n",
      "1e-06 267.93458427560887\n"
     ]
    }
   ],
   "source": [
    "def numberOfApproxDistinctNeeded(failure):\n",
    "    return (6/(0.57)**2)*math.log(2/failure)\n",
    "\n",
    "for failure in (0.1,0.01,0.001,0.00001,0.000001):\n",
    "    print(failure,numberOfApproxDistinctNeeded(failure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distinct elements, code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code for zeros. There are many ways you can do this, and in languages like C it can be done very quickly as the CPU has circuitry to compute it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeros(x):\n",
    "    answer=0\n",
    "    while x % 2 == 0:\n",
    "        x=x//2\n",
    "        answer+=1\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  has  0  zeros\n",
      "4  has  2  zeros\n",
      "16  has  4  zeros\n",
      "24  has  3  zeros\n",
      "768  has  8  zeros\n",
      "1000  has  3  zeros\n",
      "10001  has  0  zeros\n"
     ]
    }
   ],
   "source": [
    "for x in [1,4,16,24,768,1000,10001]:\n",
    "    print(x,\" has \",zeros(x),\" zeros\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is code for computing the exact number of distinct elements. It uses the fact that inserting into a set does nothing if the item is there already. Note that this uses lots of space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distinctElements(strings):\n",
    "    S=set()\n",
    "    for string in strings:\n",
    "        S.add(string)\n",
    "    return len(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code for computing the approximate number of distinct elements. It uses very little space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxZeros(strings,seed=0):\n",
    "    return max(zeros(hash((string,seed))) for string in strings )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approxDistinctElements(strings):\n",
    "    seed=random.random()\n",
    "    return int(2**(maxZeros(strings,seed)+0.5)) # the int gets rid of the clutter after the decimal point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a demo. Note that the exact method needs to store $100000\\cdot 50\\cdot 10$ characters, 50 million characters. The approximate method stores one integer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Real distinct elements:  100000\n",
      "           Maximum zeros:  17\n",
      "Approx distinct elements:  185363\n"
     ]
    }
   ],
   "source": [
    "def randomStringOfChars(length):\n",
    "    letters = \"qwertyuiopasdfghjklzxcvbnnm\"\n",
    "    return \"\".join((random.choice(letters) for i in range(length)))\n",
    "\n",
    "A=[randomStringOfChars(50) for s in range(100000)]\n",
    "print(\"  Real distinct elements: \",distinctElements(A*10)) #Five copies of A\n",
    "print(\"           Maximum zeros: \",maxZeros(A*10))\n",
    "print(\"Approx distinct elements: \",approxDistinctElements(A*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ven thee to give?\n",
      "Profitless usurer why dost thou use\n",
      "So great a sum of sums yet canst not live?\n",
      "For having traffic with thy self alone,\n",
      "Thou of thy self thy sweet self dost deceive,\n",
      "Then how when nature calls thee to be gone,\n",
      "What acceptable audit canst thou leave?\n",
      "  Thy unused beauty must be tombed with thee,\n",
      "  Which used lives th’ executor to be.\n",
      "\n",
      "\n",
      "                    5\n",
      "\n",
      "Those hours that with gentle work did frame\n",
      "The lovely gaze where every eye doth dwell\n",
      "Will play the tyrants to the very same,\n",
      "And that unfair which fairly doth excel:\n",
      "For never-resting time leads summer on\n",
      "To hideous winter and confounds him there,\n",
      "Sap checked with frost and lusty leaves quite gone,\n",
      "Beauty o’er-snowed and bareness every where:\n",
      "Then were not summer’s distillation left\n",
      "A liquid prisoner pent in walls of glass,\n",
      "Beauty’s effect with beauty were bereft,\n",
      "Nor it nor no remembrance what it was.\n",
      "  But flowers distilled though they with winter meet,\n",
      "  Leese but their show, their substance still lives sweet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f=open(\"data/shakespeare.txt\",\"r\") \n",
    "#Download http://www.gutenberg.org/files/100/100-0.txt and put it into a subdirectory called data\n",
    "\n",
    "shakespere=f.read()\n",
    "print(shakespere[5000:6000]) # Test to make sure the file is as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Project', 'Gutenberg', 'eBook', 'of', 'The', 'Complete', 'Works', 'of', 'William', 'Shakespeare', 'by', 'William', 'Shakespeare', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'You', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www', 'gutenberg', 'org', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'eBook', 'Title']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "words=re.findall(r\"[\\w']+\", shakespere) #This breaks it into words\n",
    "print(words[:100]) # Test showing the first 100 words of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Real distinct elements:  35963\n",
      "             Approx distinct elements:  11585\n",
      "Median of 99 Approx distinct elements:  46340\n"
     ]
    }
   ],
   "source": [
    "print(\"               Real distinct elements: \",distinctElements(words))\n",
    "print(\"             Approx distinct elements: \",approxDistinctElements(words))\n",
    "print(\"Median of 99 Approx distinct elements: \",[approxDistinctElements(words) for i in range(99)][50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the above code, each of the approximate distinct elements was computed separately, that is it passes through the data 99 times. As an exercise write code that only passes through the data once and returns the median approximate distinct element. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "In order to get a uniform sample in the streaming model, we needed to take the $i$th item with probability $\\frac{1}{i}$. This involves computing a random number. \n",
    "\n",
    "Recall that to compute 10%-approximate median with a failure rate of $0.01\\%$ we needed about 6000 random samples. Implemented in a straightforward way, this would mean 6000 random numbers would be needed for each data item, which is a lot!\n",
    "\n",
    "So your homework is to create an method to compute a sample in a stream that is *almost* uniform, that is that the probability to pick a given item is within a factor of two of $\\frac{1}{n}$ if the stream has had $n$ items so far. Your method instead of having $n$ random numbers generated in total should generate far fewer: a number logarithmic in $n$.\n",
    "\n",
    "Present your method, code it, and prove that it works.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
