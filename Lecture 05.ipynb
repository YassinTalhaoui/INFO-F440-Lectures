{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5\n",
    "\n",
    "# February 26 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count min sketch\n",
    "\n",
    "We are in the streaming model, and data is passing by, and each data item $x$ has an ID. Suppose we want to know, given an ID, what is number of times data with that ID has appeared in the stream, call this $c_x$? In order to answer this exactly, we would need to store a table of all ID's we have seen as well as the number of times we have seen this. Suppose we are willing to have an approximate answer, and in return have a very small structure. That is where the count-min sketch is of use.\n",
    "\n",
    "The count min sketch, given values of $\\epsilon$ and $\\delta$ will for any item $x$ compute an approximate frequency $\\hat{c}_x$ such that $c_x \\leq \\hat{c}_x$ and $\\hat{c}_x \\leq c_x + \\epsilon n$ with probability at least $1-\\delta$, where $n$ is the number of items seen so far. Thus the answer given may overestimate the frequency, but it will never underestimate it.\n",
    "\n",
    "\n",
    "The count-min sketch is a 2-dimensional array $A$ with width $w=2/\\epsilon$ and height $h=\\log \\frac{1}{\\delta}$. This is the entire structure. It thus has size $\\frac{2}{\\epsilon}\\log_2 \\frac{1}{\\delta}$. We assume we have $h$ hash functions $hash_i$, $i \\in [h]$. The two operations are increment and query:\n",
    "\n",
    "- $Increment(x)$: For all $i \\in [h]$, increment $A[i][hash_i(x)]$\n",
    "- $Query(x)$: For all $i \\in [h]$, return the smallest $A[i][hash_i(x)]$\n",
    "\n",
    "Now, lets prove that it works as claimed.\n",
    "\n",
    "Let $X_{x,i}$ be $A[i][hash_i(x)] - c_x$, that is, the number of excess items in the $i$th row for item $x$, those beyond $c_x$.\n",
    "\n",
    "We know $E[X_{x,i}] \\leq n/w$, as less than $n$ items have been added that are not $x$ and each has a probability of $1/w$ of incrementing the same bucket as $i$. Thus by Markov $Pr[X_{x,i} \\geq \\overbrace{2n/w}^{n\\epsilon}] \\leq \\frac{1}{2}$. (Note these events are *not* independent but Markov is ok with that).\n",
    "\n",
    "This is the chance that a single value is above the desired error threshold of $n\\epsilon$. But as we use the min, failure occurs when *all* $h$ locations have above the desired error threshold. Each row is computed independently, so we can just multiply, and you get that this happens with probability at most $\\delta$:\n",
    "\n",
    "$$ Pr\\left[ \\bigwedge_{i=1}^h [X_{a,i} \\geq n\\epsilon] \\right] \\leq \\frac{1}{2^h} = \\delta\n",
    "$$\n",
    "\n",
    "Thus you can get a value, accurate to within $1\\%$ additive error, with $1\\%$ failure probability using an array of size $1400$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code in a class. Most of the code is for printing things out in a nice way. The four lines of code in the `add` and `count` functions are the meat of the countmin sketch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class countMin:\n",
    "    def __init__(self,epsilon,delta,verbose=False):\n",
    "        self._w=math.ceil(2/epsilon)\n",
    "        self._h=math.ceil(math.log(1/delta,2))\n",
    "        self._epsilon=epsilon\n",
    "        self._delta=delta\n",
    "        if verbose:\n",
    "            print(\"Initializing with width=\",self._w,\n",
    "                  \" and height=\",self._h,\n",
    "                  \" total size=\",self._w*self._h,\n",
    "                  \"for epsilon=\", epsilon,\n",
    "                  \"delta=\",delta)\n",
    "        self._A=[ [0]*self._w for i in range(self._h)]\n",
    "        self._n=0\n",
    "    def __repr__(self):\n",
    "        return \"\".join( (repr(self._A[i])+\"\\n\" for i in range(self._h) ) )\n",
    "    def add(self,x,ammount=1):\n",
    "        for h in range(self._h):\n",
    "            self._A[h][hash((h,x))%self._w]+=ammount\n",
    "        self._n+=ammount\n",
    "    def count(self,x):\n",
    "        return min (self._A[h][hash((h,x))%self._w] for h in range(self._h))\n",
    "    def __len__(self):\n",
    "        return self._n\n",
    "    def printCount(self,x):\n",
    "        print(\"Count of \\\"\"+x+\n",
    "             \"\\\" is between \",max(0,self.count(x)-int(self._n*self._epsilon)),\n",
    "             \"and \",self.count(x),\n",
    "              \"with probability at least\",1-self._delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing with width= 20  and height= 7  total size= 140 for epsilon= 0.1 delta= 0.01\n",
      "[1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0]\n",
      "[0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Count of \"Tiger\" is between  1 and  1 with probability at least 0.99\n"
     ]
    }
   ],
   "source": [
    "# A simple demo   \n",
    "CM=countMin(0.1,0.01,True)\n",
    "CM.add(\"Tiger\")\n",
    "CM.add(\"Fish\")\n",
    "CM.add(\"Bird\")\n",
    "\n",
    "print(repr(CM))\n",
    "CM.printCount(\"Tiger\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a longer example where I load the collected works of Shakespeare, break it into a list of words, and then put the words into a countMin sketch and use it to estimate their frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ven thee to give?\n",
      "Profitless usurer why dost thou use\n",
      "So great a sum of sums yet canst not live?\n",
      "For having traffic with thy self alone,\n",
      "Thou of thy self thy sweet self dost deceive,\n",
      "Then how when nature calls thee to be gone,\n",
      "What acceptable audit canst thou leave?\n",
      "  Thy unused beauty must be tombed with thee,\n",
      "  Which used lives th’ executor to be.\n",
      "\n",
      "\n",
      "                    5\n",
      "\n",
      "Those hours that with gentle work did frame\n",
      "The lovely gaze where every eye doth dwell\n",
      "Will play the tyrants to the very same,\n",
      "And that unfair which fairly doth excel:\n",
      "For never-resting time leads summer on\n",
      "To hideous winter and confounds him there,\n",
      "Sap checked with frost and lusty leaves quite gone,\n",
      "Beauty o’er-snowed and bareness every where:\n",
      "Then were not summer’s distillation left\n",
      "A liquid prisoner pent in walls of glass,\n",
      "Beauty’s effect with beauty were bereft,\n",
      "Nor it nor no remembrance what it was.\n",
      "  But flowers distilled though they with winter meet,\n",
      "  Leese but their show, their substance still lives sweet.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f=open(\"data/shakespeare.txt\",\"r\") \n",
    "#Download http://www.gutenberg.org/files/100/100-0.txt and put it into a subdirectory called data\n",
    "\n",
    "shakespere=f.read()\n",
    "print(shakespere[5000:6000]) # Test to make sure the file is as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Project', 'Gutenberg', 'eBook', 'of', 'The', 'Complete', 'Works', 'of', 'William', 'Shakespeare', 'by', 'William', 'Shakespeare', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'You', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www', 'gutenberg', 'org', 'If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States', 'you', 'will', 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'eBook', 'Title']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "words=re.findall(r\"[\\w']+\", shakespere) #This breaks it into words\n",
    "print(words[:100]) # Test showing the first 100 words of the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing with width= 2000  and height= 7  total size= 14000 for epsilon= 0.001 delta= 0.01\n",
      "Words added:  983333\n"
     ]
    }
   ],
   "source": [
    "#Now, lets make a countMin sketch and add our words (in lower case)\n",
    "import string\n",
    "\n",
    "CM=countMin(epsilon=0.001,delta=0.01,verbose=True)\n",
    "for word in words:\n",
    "    CM.add(word.lower())\n",
    "print(\"Words added: \",len(CM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note our original data set had 5.8 million characters, and we have reduced this to a table of size 4000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of \"the\" is between  29281 and  30264 with probability at least 0.99\n",
      "Count of \"thy\" is between  3430 and  4413 with probability at least 0.99\n",
      "Count of \"King\" is between  0 and  105 with probability at least 0.99\n",
      "Count of \"king\" is between  2163 and  3146 with probability at least 0.99\n"
     ]
    }
   ],
   "source": [
    "CM.printCount(\"the\")\n",
    "CM.printCount(\"thy\")\n",
    "CM.printCount(\"King\") # There are none as we converted to lower case\n",
    "CM.printCount(\"king\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework\n",
    "\n",
    "With the countMin sketch, given an item we can estimate its frequency. In the Shakespeare data set, we saw that `the` was fairly frequent. But we had to know to ask about `the`. What if we wanted to know all the words with frequency above a certain threshold, such as more than $2\\epsilon n$, without having to guess what they were? Show how to modify the class above so that a method `mostFrequent()` can be added that reports the words with frequency above $2\\epsilon n$. Most importantly, you can not store all the words! As your list that you will return will be at most size $1/2\\epsilon$ you should store at most roughly that many words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
